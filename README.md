# Yigui/依柜：人人都是服装设计师

> Yigui是一款旨在将专业服装设计流程大众化、个性化的iOS应用。它打通了从"真实人体参数 → 智能3D建模 → 个性化服装设计 → 虚拟试穿"的全链路，让每一位用户都能基于自己独一无二的身体，成为自己"虚拟分身"的专属服装设计师。

## 一、核心技术架构与实现创新

Yigui的技术核心是构建了一条高效、自动化、且充分保护用户隐私的数据与模型处理管线。该管线由客户端（iOS App）和服务器端（Model Server）协同工作，以前端轻量化、后端集约化的方式，实现了专业级的3D数字人与服装的生成和试穿体验。

### 1.1 客户端：基于CoreML的"隐私优先"与"迭代收敛"体型预测

为了将用户的身高、体重两个基础数据，转化为精确的3D模型比例参数，我们并未使用传统的网络请求将敏感数据上传云端处理，而是创新性地在iOS客户端本地完成所有预测。

**技术实现：**
- **本地化CoreML部署**：我们将`胸围`、`腰围`、`大腿围`三个关键比例的预测模型（`Chest_Ratio.mlmodel`, `Waist_Ratio.mlmodel`, `Thigh_Ratio.mlmodel`）直接部署在App内。这从根本上杜绝了用户身高体重等隐私信息离开设备，响应速度快，且支持离线使用。
- **"迭代收敛"预测算法**：我们发现，人体各部位的比例并非相互独立，而是存在复杂的循环依赖。例如，胸围的大小会影响腰围的视觉比例，反之亦然。为解决此问题，我们设计了一套**迭代收敛预测**算法。在`BodyShapePredictorService`中，程序会进行3轮循环计算：将第一轮预测出的胸围比例作为第二轮预测腰围的输入，再将更新后的胸、腰数据用于预测大腿围，如此往复。这使得预测结果能在数次迭代后达到一个稳定且内部逻辑自洽的精确值，极大提升了3D模型的还原度。

[ **此处可插入一张图：CoreML迭代收敛算法流程图，展示三轮迭代中数据如何在三个模型间流动与修正** ]

### 1.2 服务器端：基于Blender的"模块化虚拟装配"流水线

服务器端（Model Server）负责处理客户端预测出的比例参数，并执行高精度的3D模型处理。我们基于Python的FastAPI框架构建了一套异步任务系统，并通过命令行调用Blender的Python脚本，实现了一套我们称之为"虚拟装配"的高效模型生成管线。

**技术实现：**
1.  **异步任务队列**：当客户端请求生成模型或试穿时，服务器会立即返回一个`task_id`，并将耗时的Blender渲染任务放入后台执行。客户端则通过此ID轮询检查任务状态。这种设计避免了长时间等待导致的UI卡顿，优化了用户体验。
2.  **原子化部件处理**：我们并未对一个完整的人物模型进行变形，而是将其"原子化"为`身体`、`上衣`、`裤子`等独立部件。Blender脚本（如`process_single_part.py`）会根据传入的比例参数，对每一个部件模型进行独立的、非破坏性的骨骼缩放和网格调整。
3.  **动态"虚拟装配"**：
    - **首次生成**：所有部件独立处理完成后，另一个Blender脚本（`merge_parts.py`）会将这些缩放好的部件重新组装成一个完整的、合体的数字人模型，并作为用户的`基础模型`存入数据库，同时记录其所有"零件"的源文件ID。
    - **虚拟试穿**：这是该架构最核心的优势。当用户需要试穿一件新设计的衣服时，系统并非从头开始。`run_wear_item_pipeline`函数会智能地找到用户的基础模型，获取其原始零件ID，然后仅用新的服装部件替换掉对应部位（如用新上衣替换旧上衣），再与原有的身体和裤子等"旧零件"进行快速重组。

这种"先拆解、再缩放、后重组"的**虚拟装配**模式，极大提升了模型处理的复用性和效率，使得每次试穿的后台处理时间大幅缩短，实现了轻快、流畅的虚拟试穿体验。

[ **此处可插入一张图：后端"虚拟装配"模型流水线示意图，展示从API请求到部件处理再到合并输出的全过程** ]

[ **此处可插入一张图：人物模型展示截图，展示不同身高体重参数下的模型变化** ]

## 二、现阶段核心功能闭环实现

基于上述技术架构，Yigui目前已完成所有核心功能的最小可行性闭环，为用户提供了一套完整的"创作者"体验。

1.  **专属虚拟形象生成**：用户在引导页输入身高、体重、昵称等基础信息后，应用通过前述的"CoreML预测 + 后端装配"流程，在数秒内即可生成一个与用户真实身材比例高度一致的专属3D虚拟形象。
2.  **简洁直观的服装设计**：在设计模块，我们目前提供了`卫衣`、`T恤`、`裤子`、`短裤`四种基础版型。用户可以像"填色游戏"一样，轻松为服装更换纯色，或从手机相册上传任意图片作为自定义印花。所有设计参数（如颜色、印花贴图路径）都会被记录在数据库的`DesignProject`表中。
3.  **云端衣柜与一键试穿**：用户的每一件设计作品都会被保存在"我的衣柜"中，并按`上装`、`下装`等类别清晰分类。用户可以随时在衣柜中选择任意作品，点击"试穿"即可触发后端的"虚拟装配"流程，将该服装"穿"在自己的3D模型上进行实时预览和搭配。
4.  **模型与作品管理**：用户可以保存多个版本的3D模型和设计作品，并自由切换当前激活的模型，实现了完整的"创作-管理-预览"闭环。

[ **此处可插入一张图：服装设计界面截图，展示颜色选择和自定义印花功能** ]

[ **此处可插入一张图：云端衣柜界面截图，展示已保存的服装作品** ]

[ **此处可插入一张图：虚拟试穿效果截图，展示模型穿着用户设计的服装** ]

## 三、下一阶段目标与展望

我们深知，目前的Yigui只是实现了我们"人人都是服装设计师"愿景的第一步。虽然核心链路已经跑通，但我们仍在全力以赴，向着更远大的目标迈进。

1.  **实现"照片级"真实感建模** (开发中)：当前版本依赖用户输入身高体重，下一步的核心目标是利用iPhone的摄像头，结合**摄影测量法**与**计算机视觉**技术，让用户通过拍摄几张自己的照片，就能自动生成与本人外貌和体型都高度相似的3D数字人。我们正在探索利用ARKit和RealityKit的相关能力，以实现这一飞跃。
2.  **打造"移动端CLO3D"的专业设计体验** (开发中)：当前的"贴图式"设计功能相对初级。我们的长远目标是提供更强大的设计工具，包括但不限于：
    - **版型编辑**：允许用户通过参数化或可视化拖拽的方式，调整服装的袖长、腰线、轮廓等。
    - **面料模拟**：引入基于物理的渲染（PBR）和布料模拟系统，让不同材质（如棉、丝绸、牛仔布）的服装在模型身上呈现出逼真的褶皱和动态效果。
    - **配饰与细节**：增加如纽扣、拉链、口袋等更多细节组件，提升设计的丰富度和真实感。

我们坚信，个性化创作的浪潮势不可挡，而技术的使命就是不断降低创作的门槛。Yigui正行走在这条道路上，我们致力于将强大的设计能力赋予每一位热爱生活、渴望表达的普通人。我们期待Yigui能成为未来个性化定制电商、虚拟社交形象、乃至康复辅具评估等领域的重要工具。

[ **此处可插入一张图：未来功能的概念设计图或原型图** ] 
